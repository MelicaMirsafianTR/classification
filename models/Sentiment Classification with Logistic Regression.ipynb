{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b158fa65",
   "metadata": {},
   "source": [
    "## Loading the input dataset\n",
    "This is a dataset of movie reviews scraped from Imdb. You can find it for download on **Kaggle** here:\n",
    "https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews  \n",
    "I have already downloaded this dataset and put in the local directory the same as this notebook.  \n",
    "Kaggle is a treasure chest of publicly available datasets with community contributed code for cleaning and prediction! If you're interested in more tutorials like this, pay a visit there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "67687a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0eb0eabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c2afc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No one expects the Star Trek movies to be high art, but the fans do expect a movie that is as good as some of the best episodes. Unfortunately, this movie had a muddled, implausible plot that just left me cringing - this is by far the worst of the nine (so far) movies. Even the chance to watch the well known characters interact in another movie can't save this movie - including the goofy scenes with Kirk, Spock and McCoy at Yosemite.<br /><br />I would say this movie is not worth a rental, and hardly worth watching, however for the True Fan who needs to see all the movies, renting this movie is about the only way you'll see it - even the cable channels avoid this movie.\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].iloc[49999]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff16c39",
   "metadata": {},
   "source": [
    "### Power in Numbers!\n",
    "There is great power in big numbers! The larger the dataset, the greater the power given to the model to learn detailed patterns. Which in turn will lead to more accurate predictions!  \n",
    "In this tutorial we take a random smaller sample to make things faster, but the more you use the better the accuracy will be (most of the time, **except when \"Garbage in Garbage out\"**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c1d7f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "848be3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    2565\n",
       "positive    2435\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690b965",
   "metadata": {},
   "source": [
    "The dataset seems to be roughly balanced, but if it wasn't we could have taken measures to accommodate for better learning on the class with lower representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8a74a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {'positive': 1, \"negative\": 0}\n",
    "reverse_class_mapping = {v: k for k, v in class_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c75cfc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert positive and negative in 0 and 1 format\n",
    "df['sentiment'].replace({'positive':1,\"negative\":0},inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c9e56116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189      0\n",
       "4536     0\n",
       "36924    1\n",
       "19830    1\n",
       "40655    0\n",
       "        ..\n",
       "7912     0\n",
       "23148    0\n",
       "26603    0\n",
       "41193    0\n",
       "42349    1\n",
       "Name: sentiment, Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea26898d",
   "metadata": {},
   "source": [
    "### Cleaning and preprocessing\n",
    "This part usually requires the most work in Data Science and is a very essential step in the process. We need to understand the data by looking at it, understand if it is dirty and how it can be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8dea1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def text_normalization(txt:str, to_lower :bool=True, no_punct :bool=True) -> str:\n",
    "    # remove all non-alphabet items including punctuation except the dash i.e. for well-thought\n",
    "    if no_punct:\n",
    "        txt = re.sub('(^\\(?[^()]*\\))|([^a-zA-Z0-9\\s]+)', '', txt)\n",
    "    \n",
    "      # remove multiple empty spaces and replace with one\n",
    "    txt = re.sub('[^\\S]+',' ', txt)\n",
    "    \n",
    "    # apply lowercase\n",
    "    if to_lower:\n",
    "         txt = txt.lower()\n",
    "\n",
    "    cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    txt = re.sub(cleanr, '', txt) \n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "20b923fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove the stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return [t for t in tokens if t not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0235d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    y =[]\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    z = y[:]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5987940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list into string\n",
    "def join_back(list_input):\n",
    "    return \" \".join(list_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0ed12",
   "metadata": {},
   "source": [
    "Pulling all the preprocessing functions into one functio to ease the application to all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "16d1a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text_normalization(text)\n",
    "    text = remove_stopwords(text)\n",
    "    tokens = stem_words(text)\n",
    "    tokens = join_back(tokens)\n",
    "   \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6116a1",
   "metadata": {},
   "source": [
    "**progress_apply** is a capability added by tqdm to keep track of progress as a method is being applied to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4234afee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73006f7fabed4f14934eb04aa5c8cf1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df['reviews_preprocessed'] = df['review'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3034060",
   "metadata": {},
   "source": [
    "## Vectorizing the input - transformation into a vector space\n",
    "For the model to understand anything about the input, the input needs to be transformed into numbers as opposed to text! human language on its own does not mean anything to an algorithm. So how do we do this?  \n",
    "There are many options for transforming text input into a vector space. One of the most simplest methods is:  \n",
    "**bag-of-words**: simply count the occurrence of each word and record it under its own column. For example given a corpus of documents below:\n",
    "```\n",
    "[\"My cats are very polite\",\n",
    "\"I play videogames on the weekends\",\n",
    "\"This machine does not have enough capacity\"]\n",
    "```\n",
    "and for input = `\"I have two cats\"` the corresponding transformation would look something like this:\n",
    "\n",
    "| WORDS | my | cats | are | very | polite | I | play | videogames | on | weekends | machine | does | not | have | two | cpus |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| VECTOR | 0 | **1** | 0 | 0 | 0 | **1** | 0 | 0 | 0 | 0 | 0 | 0 | 0 | **1** | **1** | 0 |\n",
    "\n",
    "\n",
    "This method first creates a dictionary of all words present in the corpus, then counts their frequency in each document and creates the vector\n",
    "\n",
    "**Note**: There are way more sophisticated transformation techniques such as **word embeddings trained using deep learning**, **tf-idf vectorization**, and many more! The word embeddings themselves come in a huge variety of flavours and all you need to do is give it a search. You'll find options from **GloVe**, **SBERT**, Google's **Word2Vec**, to **fasttext** and more. These are pre-trained transformation dictionaries that you can just download and use.\n",
    "  \n",
    "In this tutorial we will use the simple **bag-of-words** method. For all its simplicity, it is highly explainable and very useful for understanding the basics of natural language processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c29c9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "89fa8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(df['reviews_preprocessed']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425812c2",
   "metadata": {},
   "source": [
    "### What does the data look like at this point?\n",
    "Just a series of binary values! **Computer goes YUMMM!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "df173fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bc954199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract y\n",
    "y = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3123a9",
   "metadata": {},
   "source": [
    "### Train set and Test (hold-out) set\n",
    "In order to verify if the model is actually learning anything, we need to split the full dataset at hand into a training set and a hold-out set (test set). A typical split ratio can be **80% for train** and **20% for test set**, but depending on data availability this can be changed.\n",
    "- The **training set** will be used to teach the model patterns existing in the data that would lead to a Positive sentiment or a Negative sentiment.  \n",
    "- The **test set** will be kept away from the model during training and only used to get predictions and to verify those predictions. This will allow for an important step in any machine learning process: **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5bd973e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b41163",
   "metadata": {},
   "source": [
    "## Training a simple classifier with Logistic Regression\n",
    "Logistic Regression is one of the simple Machine Learning algorithms that operates on the assumption that there is a linear pattern in the data between the input and the target variable. It is quick to train and get predictions from, and it is easy to work with and understand.  \n",
    "In this tutorial we will use Logistic Regression with its default parameters, but there are hyperparameters that can be tuned in order to get better accuracy. You can view all the possible hyperparameters here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "18854675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f0c58744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "390437e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d15e16d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melica/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "739a4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b210b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"logreg\",accuracy_score(y_test,y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f11c70",
   "metadata": {},
   "source": [
    "### Calculating False Negative Rate and False Positive Rate\n",
    "- False Negative rate: How many reviews were **actually positive** but we predicted them as **negative incorrectly**\n",
    "- False Positive rate: How many reviews were **actually negative** but we predicted them as **positive incorrectly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1a0c14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cfca90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to what a function or class in python does? just try putting '?' after its name and run it like below\n",
    "confusion_matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b79f841",
   "metadata": {},
   "source": [
    "Confusion matrix whose i-th row and j-th column entry indicates the number of samples with true label being i-th class and predicted label being j-th class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0e3379cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[429,  85],\n",
       "       [ 65, 421]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb010ff7",
   "metadata": {},
   "source": [
    "### Getting predictions for new/custom input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d6dd22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\n",
    "    \"we enjoyed this movie a lot\",\n",
    "    \"we hated this movie\",\n",
    "    \"do not take your children to this movie. too scary!\",\n",
    "    \"I could watch this movie over and over again\",\n",
    "    \"I can watch this forever\",\n",
    "    \"It started off great but went downhill too fast. Struggled to stay awake.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8d0b82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(input_tokens, vectorizer):\n",
    "    return vectorizer.transform([input_tokens]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3d570fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['positive'], Review: we enjoyed this movie a lot\n",
      "Prediction: ['negative'], Review: we hated this movie\n",
      "Prediction: ['negative'], Review: do not take your children to this movie. too scary!\n",
      "Prediction: ['negative'], Review: I could watch this movie over and over again\n",
      "Prediction: ['positive'], Review: I can watch this forever\n",
      "Prediction: ['negative'], Review: It started off great but went downhill too fast. Struggled to stay awake.\n"
     ]
    }
   ],
   "source": [
    "for review in input_list:\n",
    "    numeric_predictions = clf.predict(vectorize(preprocess(review), cv))\n",
    "    readable_predictions = [reverse_class_mapping[p] for p in numeric_predictions]\n",
    "    print(f\"Prediction: {str(readable_predictions)}, Review: {review}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c695a6",
   "metadata": {},
   "source": [
    "### How do you think the model did on these custom reviews?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
